{
  "app": {
    "title": "Ollama Model Manager",
    "description": "Manage your local Ollama models"
  },
  "nav": {
    "overview": "Overview",
    "pull": "Pull Model",
    "create": "Create Model",
    "chat": "Chat",
    "settings": "Settings"
  },
  "models": {
    "title": "Models",
    "installed": "Installed Models",
    "running": "Running Models",
    "name": "Name",
    "size": "Size",
    "diskUsage": "Disk Usage",
    "vramUsage": "VRAM Usage",
    "ramUsage": "RAM Usage",
    "status": "Status",
    "loaded": "Loaded",
    "unloaded": "Unloaded",
    "expiresAt": "Expires At",
    "expiresIn": "Expires In",
    "never": "Never",
    "modifiedAt": "Modified At",
    "contextLength": "Context Length",
    "digest": "Digest",
    "actions": "Actions",
    "showDetails": "Show Details",
    "delete": "Delete",
    "noModels": "No models found",
    "noRunningModels": "No running models",
    "search": "Search models...",
    "filter": "Filter",
    "utilization": "Utilization",
    "loadSuccess": "Model loaded successfully",
    "unloadSuccess": "Model unloaded successfully",
    "run": "Run",
    "stop": "Stop"
  },
  "stats": {
    "sizeDistribution": "Size Distribution",
    "modelSizes": "Top Models by Size",
    "statusDistribution": "Status Distribution",
    "vramUsage": "VRAM Usage (Running)"
  },
  "chat": {
    "title": "Chat",
    "description": "Test your models with an interactive chat",
    "selectModel": "Select Model",
    "selectModelDescription": "Choose a model to chat with. Running models are indicated.",
    "selectModelPlaceholder": "Select a model...",
    "model": "Model",
    "loadModel": "Load Model",
    "modelNotRunning": "Model Not Running",
    "modelNotRunningDescription": "The selected model is not currently running. Click \"Load Model\" above to start it.",
    "noModelSelected": "No Model Selected",
    "noModelSelectedDescription": "Select a model from the dropdown above to start chatting.",
    "chattingWith": "Chatting with",
    "clear": "Clear",
    "cleared": "Chat cleared",
    "startConversation": "Start a conversation",
    "typeMessage": "Type a message below to begin",
    "placeholder": "Type your message...",
    "thinking": "Thinking...",
    "thinkingProcess": "Thinking Process",
    "reasoning": "Reasoning...",
    "hint": "Press Enter to send, Shift+Enter for new line"
  },
  "modelDetails": {
    "title": "Model Details",
    "parameters": "Parameters",
    "system": "System Prompt",
    "template": "Template",
    "messages": "Messages",
    "capabilities": "Capabilities",
    "details": "Details",
    "license": "License",
    "modelfile": "Modelfile",
    "close": "Close"
  },
  "pull": {
    "title": "Pull Model",
    "description": "Download a model from Ollama registry or Hugging Face",
    "selectSource": "Select Model Source",
    "modelName": "Model Name",
    "modelNamePlaceholder": "e.g., deepseek-r1:8b",
    "pull": "Pull Model",
    "pulling": "Pulling...",
    "success": "Model pulled successfully",
    "error": "Failed to pull model",
    "cancel": "Cancel",
    "browseModels": "Browse models at",
    "quickSelect": "Quick Select",
    "advancedOptions": "Advanced Options",
    "sources": {
      "ollama": {
        "label": "Ollama Library",
        "description": "Official models from Ollama registry"
      },
      "huggingface": {
        "label": "Hugging Face",
        "description": "GGUF models from Hugging Face Hub"
      },
      "gguf": {
        "label": "GGUF File",
        "description": "Direct GGUF files with specific quantization"
      },
      "custom": {
        "label": "Custom Registry",
        "description": "Models from your own Ollama registry server"
      },
      "hfDataset": {
        "label": "Dataset Images",
        "description": "Download images from Hugging Face datasets"
      }
    },
    "hfFormat": "Hugging Face Format",
    "hfLatest": "Latest GGUF file",
    "hfQuantized": "Specific quantization (Q4_K_M, Q5_K_M, etc.)",
    "ggufFormat": "GGUF Quantization Options",
    "q4km": "Good balance of quality and size",
    "q5km": "Higher quality, larger size",
    "q8": "Highest quality, largest size",
    "ollamaFormat": "Ollama Model Format",
    "ollamaDefault": "Default/latest version",
    "ollamaTag": "Specific version (7b, 13b, etc.)",
    "ollamaNamespace": "Community model",
    "customFormat": "Custom Registry Format",
    "customBasic": "Model from custom registry",
    "customTag": "Specific version/tag",
    "customNamespace": "Model with namespace",
    "customTip": "Your registry must be running Ollama and accessible from your network.",
    "hfDatasetFormat": "Hugging Face Dataset Format",
    "datasetPath": "Dataset Path",
    "datasetPathPlaceholder": "org/dataset-name",
    "datasetPathHint": "Enter the dataset path (e.g., mozilla-foundation/common_voice_11_0)",
    "imagePath": "Image Path",
    "imagePathPlaceholder": "images/sample.png",
    "imagePathHint": "Enter the path to the image within the dataset",
    "preview": "Preview",
    "previewing": "Loading preview...",
    "download": "Download",
    "downloading": "Downloading...",
    "downloadSuccess": "Image downloaded successfully",
    "downloadError": "Failed to download image",
    "previewError": "Failed to load preview",
    "imageSize": "Size",
    "imageType": "Type",
    "savedTo": "Saved to",
    "hfDatasetExamples": "Example datasets",
    "browseDatasets": "Browse datasets at"
  },
  "create": {
    "title": "Create Model",
    "description": "Create a new model from base model or Modelfile",
    "mode": "Mode",
    "fromFields": "From Fields",
    "fromModelfile": "From Modelfile",
    "baseModel": "Base Model",
    "baseModelPlaceholder": "e.g., deepseek-r1:8b",
    "modelName": "Model Name",
    "modelNamePlaceholder": "e.g., my-custom-model",
    "systemPrompt": "System Prompt",
    "systemPromptPlaceholder": "Enter system prompt...",
    "template": "Template",
    "templatePlaceholder": "Enter template...",
    "parameters": "Parameters",
    "parametersPlaceholder": "temperature: 0.7",
    "messages": "Messages",
    "modelfile": "Modelfile",
    "modelfilePlaceholder": "FROM deepseek-r1:8b\nSYSTEM You are a helpful assistant.\nPARAMETER temperature 0.7",
    "create": "Create Model",
    "creating": "Creating...",
    "success": "Model created successfully",
    "error": "Failed to create model",
    "cancel": "Cancel"
  },
  "delete": {
    "title": "Delete Model",
    "confirm": "Are you sure you want to delete this model?",
    "modelName": "Model: {{name}}",
    "diskFreed": "Disk space to be freed: {{size}}",
    "delete": "Delete",
    "deleting": "Deleting...",
    "cancel": "Cancel",
    "success": "Model deleted successfully",
    "error": "Failed to delete model"
  },
  "common": {
    "loading": "Loading...",
    "error": "Error",
    "success": "Success",
    "refresh": "Refresh",
    "close": "Close",
    "save": "Save",
    "cancel": "Cancel",
    "confirm": "Confirm",
    "yes": "Yes",
    "no": "No",
    "gb": "GB",
    "mb": "MB",
    "bytes": "bytes",
    "unknown": "Unknown"
  },
  "downloads": {
    "title": "Downloads",
    "downloading": "Downloading {{count}} model(s)",
    "completed": "Downloads completed",
    "overall": "overall",
    "cancel": "Cancel",
    "clear": "Clear",
    "clearCompleted": "Clear completed",
    "pending": "Pending...",
    "preparing": "Preparing download...",
    "pulling": "Pulling layer...",
    "verifying": "Verifying...",
    "success": "Download complete!",
    "error": "Download failed",
    "cancelled": "Download cancelled",
    "noDownloads": "No active downloads",
    "startDownload": "Start Download",
    "downloadInBackground": "Download will continue in background",
    "alreadyDownloading": "This model is already downloading"
  },
  "settings": {
    "title": "Settings",
    "description": "Configure your Ollama Dashboard",
    "apiConfiguration": "API Configuration",
    "apiConfigurationDescription": "Configure the Ollama API endpoint. Use this to connect to remote Ollama instances.",
    "apiUrl": "API URL",
    "apiUrlHint": "Enter the full URL including /api (e.g., http://192.168.1.100:11434/api)",
    "test": "Test",
    "connectionSuccess": "Connection successful!",
    "connectionFailed": "Connection failed",
    "connectionError": "Could not connect to Ollama API",
    "commonUrls": "Quick Select",
    "currentConfig": "Current Configuration",
    "saved": "Settings saved",
    "reset": "Reset to Default"
  }
}

